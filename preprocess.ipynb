{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入所有原始数据并合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('input/train.csv')\n",
    "members = pd.read_csv('input/members.csv')\n",
    "songs = pd.read_csv('input/songs.csv')\n",
    "song_extra_info = pd.read_csv('input/song_extra_info.csv')\n",
    "\n",
    "data = train.merge(members, left_on='msno', right_on='msno', how='left') \\\n",
    "        .merge(songs, left_on='song_id', right_on='song_id', how='left') \\\n",
    "        .merge(song_extra_info, left_on='song_id', right_on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连续型特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "\n",
    "# 标准化\n",
    "scalar = StandardScaler()\n",
    "song_length_norm = pd.DataFrame(scalar.fit_transform(data[['song_length']]), columns=['song_length_norm'])\n",
    "\n",
    "# 分位数变换\n",
    "song_count = data.groupby('song_id').agg(song_count=('msno', 'count'))\n",
    "song_count_feature = data[['song_id']].merge(song_count, left_on='song_id', right_on='song_id', how='left')\n",
    "quant = QuantileTransformer(n_quantiles=10000)\n",
    "song_count_quant = pd.DataFrame(quant.fit_transform(song_count_feature['song_count'].values.reshape(-1, 1)), columns=['song_count_quant'])\n",
    "\n",
    "# 离散化\n",
    "data['bd_dist'] = data['bd'].clip(0, 60).replace(0, np.nan).apply(lambda x: x // 5) # 处理异常值后分桶\n",
    "bd_onehot = pd.get_dummies(data['bd_dist'], columns=['bd_dist'], dummy_na=True, prefix='bd', prefix_sep='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类别类特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot\n",
    "onehot_columns = ['source_system_tab', 'source_screen_name', \n",
    "            'source_type', 'language', 'city', 'gender', 'registered_via']\n",
    "data_onehot = pd.get_dummies(data[onehot_columns + ['target','msno']], \\\n",
    "                                dummy_na=True, columns=onehot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 编号\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data_label = []\n",
    "for column in onehot_columns:\n",
    "    le = LabelEncoder()\n",
    "    data_label.append(le.fit_transform(data[column].astype(str)).reshape(-1, 1))\n",
    "\n",
    "data_label_df = pd.DataFrame(np.concatenate(data_label, axis=1), columns=onehot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hash方法\n",
    "\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from collections import Counter\n",
    "\n",
    "hash_columns = ['genre_ids', 'artist_name', 'composer', 'lyricist']\n",
    "\n",
    "hash_df_map = {}\n",
    "feature_size = 16\n",
    "for column in hash_columns:\n",
    "    feature_hash = FeatureHasher(n_features=feature_size, input_type='dict')\n",
    "    data_count = data[column].apply(lambda x: Counter(str(x).split('|'))).values\n",
    "    hash_arr = feature_hash.fit_transform(data_count).todense()\n",
    "    hash_df_map[column] = pd.DataFrame(hash_arr, columns=[column + '_' + str(i) for i in range(feature_size)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户，歌曲id编号\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def encode_label(df, field):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[field])\n",
    "    df[field + \"_raw\"] = df[field]\n",
    "    # 从1开始编号，编号0留作embedding padding用\n",
    "    df[field] = le.transform(df[field]) + 1 \n",
    "    \n",
    "encode_label(data, 'msno')\n",
    "encode_label(data, 'song_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按用户切分：1. 方便复现 2. 避免数据穿越\n",
    "import hashlib\n",
    "\n",
    "data['global_index'] = data.index\n",
    "data['is_train'] = data['msno_raw'] \\\n",
    "    .apply(lambda x: int(hashlib.md5(x.encode('utf-8')).hexdigest(), 16) % 10 != 9)\n",
    "\n",
    "data_merged = data[['global_index', 'target', 'is_train', 'msno', 'song_id', 'msno_raw', 'song_id_raw']] \\\n",
    "    .merge(song_length_norm, left_index=True, right_index=True) \\\n",
    "    .merge(song_count_quant, left_index=True, right_index=True) \\\n",
    "    .merge(bd_onehot, left_index=True, right_index=True) \\\n",
    "    .merge(data_onehot.drop(['target', 'msno'], axis=1), left_index=True, right_index=True) \\\n",
    "    .merge(data_label_df, left_index=True, right_index=True) \\\n",
    "    .merge(hash_df_map['genre_ids'], left_index=True, right_index=True) \\\n",
    "    .merge(hash_df_map['artist_name'], left_index=True, right_index=True) \\\n",
    "    .merge(hash_df_map['composer'], left_index=True, right_index=True) \\\n",
    "    .merge(hash_df_map['lyricist'], left_index=True, right_index=True) \n",
    "    \n",
    "data_merged = data_merged.fillna(0)\n",
    "data_merged.columns = [c.split('.')[0].replace(' ', '_') for c in data_merged.columns]\n",
    "\n",
    "data_merged[data_merged['is_train'] == False].drop(['is_train'], axis=1).reset_index(drop=True).to_csv('./preprocess/val.csv', index=False)\n",
    "data_merged[data_merged['is_train'] == True].drop(['is_train'], axis=1).reset_index(drop=True).to_csv('./preprocess/train.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e15f193685a6a94d0df1190187b1eff96c77b6be035d78e7ca11239be60d1df3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
