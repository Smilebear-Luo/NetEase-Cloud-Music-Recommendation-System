{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fields = [\"city\", \"gender\", \"source_type\", \"source_screen_name\",\n",
    "     \"source_system_tab\", \"song_length_norm\", \"song_count_quant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_count = pd.read_csv(\"feature/song_play_count.csv\")\n",
    "unigrams = [0]+song_count['song_play_count'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer:\n",
    "    def __init__(self, vocab_size, embedding_dim, var_scope,padding_size = 0,flatten=True):\n",
    "        self.var_scope = var_scope\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.flatten = flatten\n",
    "        if padding_size==0:\n",
    "            with tf.variable_scope(self.var_scope):\n",
    "                self.embedding_matrix = tf.get_variable(shape=[vocab_size, embedding_dim], dtype=tf.float32,\n",
    "                                                        name=\"embedding_matrix\", trainable=True,\n",
    "                                                        initializer=tf.glorot_uniform_initializer())\n",
    "        else:\n",
    "            with tf.variable_scope(self.var_scope):\n",
    "                self.padding_mat = tf.zeros(shape=[padding_size,embedding_dim],dtype=tf.float32,name=\"padding_mat\")\n",
    "                self.embedding_matrix_ = tf.get_variable(shape=[vocab_size-padding_size, embedding_dim], dtype=tf.float32,\n",
    "                                                        name=\"embedding_matrix_\", trainable=True,\n",
    "                                                        initializer=tf.glorot_uniform_initializer())\n",
    "                self.embedding_matrix = tf.concat([self.padding_mat,self.embedding_matrix_],axis=0,name=\"embedding_matrix\")\n",
    "\n",
    "    def __call__(self, input_index):\n",
    "        with tf.variable_scope(self.var_scope):\n",
    "            input_identity = tf.cast(input_index, tf.int32, name=\"lookup_index\")\n",
    "            result = tf.nn.embedding_lookup(self.embedding_matrix, input_identity,\n",
    "                                                  name=\"lookup_result\")\n",
    "            if self.flatten:\n",
    "                return tf.squeeze(result,axis=[1])\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_path,user_play_song_seq_data_path,max_seq_length,input_fields):\n",
    "    data = pd.read_csv(data_path)\n",
    "    data = data[data['target']==1]\n",
    "    user_play_song_seq_data = pd.read_csv(user_play_song_seq_data_path)\n",
    "    data = data.merge(user_play_song_seq_data, on=['msno', 'global_index'], how=\"left\")\n",
    "    data['user_play_seq'] = data['song_seq'].apply(lambda x: process_user_play_song_seq_feature(x,max_seq_length))\n",
    "    feature_cols = input_fields\n",
    "    cols = feature_cols + ['song_id'] + ['user_play_seq']\n",
    "    return data.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_play_song_seq_feature(feature,max_seq_length):\n",
    "    feature_str = str(feature)\n",
    "    if feature_str is None or feature_str==\"\" or feature_str==\"nan\":\n",
    "        return np.zeros(shape=(max_seq_length),dtype=float)\n",
    "    else:\n",
    "        split_array = [float(i) for i in feature_str.split(\",\")]\n",
    "        if len(split_array)==max_seq_length:\n",
    "            return np.asarray(split_array)\n",
    "        elif len(split_array)>max_seq_length:\n",
    "            return np.asarray(split_array)[:max_seq_length]\n",
    "        else:\n",
    "            np_array = np.asarray(split_array)\n",
    "            return np.hstack([np.zeros((max_seq_length-len(np_array))),np_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YtbDNN:\n",
    "    def __init__(self,input_fields,unigrams):\n",
    "        self.negative_sample_size = 4000\n",
    "        self.batch_size = 100\n",
    "        self.input_fields = input_fields\n",
    "        self.user_play_seq_max_length=10\n",
    "        self.lr = 0.001\n",
    "        self.epochs = 2\n",
    "        self.inputs = {}\n",
    "        self.topk = 50\n",
    "        self.unigrams = unigrams\n",
    "        self.mlp_size_config = [256,128,16]\n",
    "        self.embedding_config = {\n",
    "            \"gender\": {\"vocab_size\": 3, \"embedding_dim\": 2, \"padding_size\": 0},\n",
    "            \"city\": {\"vocab_size\": 21, \"embedding_dim\": 4, \"padding_size\": 0},\n",
    "            \"song_id\": {\"vocab_size\": 359967, \"embedding_dim\": 16, \"padding_size\": 1},\n",
    "            \"inference_song_id\": {\"vocab_size\": 359967, \"embedding_dim\": 16, \"padding_size\": 1},\n",
    "            \"source_type\": {\"vocab_size\": 13, \"embedding_dim\": 4, \"padding_size\": 0},\n",
    "            \"source_screen_name\": {\"vocab_size\": 21, \"embedding_dim\": 4, \"padding_size\": 0},\n",
    "            \"source_system_tab\": {\"vocab_size\": 9, \"embedding_dim\": 4, \"padding_size\": 0}\n",
    "        }\n",
    "        self.build()\n",
    "\n",
    "    def build_mlp_layer(self,input_features):\n",
    "        net = tf.identity(input_features, \"input_op\")\n",
    "        for units in self.mlp_size_config:\n",
    "            net = tf.layers.dense(net, units=units, activation=tf.nn.relu,\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.0005),\n",
    "                                  kernel_initializer=tf.glorot_normal_initializer())\n",
    "        return net\n",
    "\n",
    "\n",
    "    def avg_pooling(self,seq_embedding,seq_length):\n",
    "        embedding_sum = tf.reduce_sum(seq_embedding,axis=1)\n",
    "        length = tf.cast(seq_length,dtype=tf.float32)\n",
    "        avg_emb = tf.div(embedding_sum,length,name=\"avg_pooling_embedding\")\n",
    "        return avg_emb\n",
    "\n",
    "\n",
    "    def build_embedding_layer(self,feature_name,flatten=True):\n",
    "        f_vocab_size = self.embedding_config[feature_name]['vocab_size']\n",
    "        f_embedding_size = self.embedding_config[feature_name]['embedding_dim']\n",
    "        f_padding_size = self.embedding_config[feature_name]['padding_size']\n",
    "        return EmbeddingLayer(f_vocab_size,f_embedding_size,feature_name,f_padding_size,flatten)\n",
    "\n",
    "    # 定义网络的结构和输入\n",
    "    def build(self):\n",
    "        ## 定义输入的placeholder，后缀ph是placeholder的缩写\n",
    "        self.source_type_ph = tf.placeholder(dtype=tf.int64,shape=[None,1],name=\"source_type\")\n",
    "        self.inputs[\"source_type\"] = self.source_type_ph\n",
    "        self.source_screen_name_ph = tf.placeholder(dtype=tf.int64,shape=[None,1],name=\"source_screen_name\")\n",
    "        self.inputs[\"source_screen_name\"] = self.source_screen_name_ph\n",
    "        self.source_system_tab_ph = tf.placeholder(dtype=tf.int64,shape=[None,1],name=\"source_system_tab\")\n",
    "        self.inputs[\"source_system_tab\"] = self.source_system_tab_ph\n",
    "        self.gender_ph = tf.placeholder(dtype=tf.int64,shape=[None,1],name=\"gender\")\n",
    "        self.inputs[\"gender\"] = self.gender_ph\n",
    "        self.city_ph = tf.placeholder(dtype=tf.int64,shape=[None,1],name=\"city\")\n",
    "        self.inputs[\"city\"] = self.city_ph\n",
    "        self.label_ph = tf.placeholder(dtype=tf.int64,shape=[None,1],name=\"label\")\n",
    "        self.inputs[\"label\"] = self.label_ph\n",
    "        self.user_play_seq_ph = tf.placeholder(dtype=tf.float64,shape=[None,self.user_play_seq_max_length],name=\"user_play_seq\")\n",
    "        self.inputs[\"user_play_seq\"] = self.user_play_seq_ph\n",
    "        self.song_length_norm_ph = tf.placeholder(dtype=tf.float64,shape=[None,1],name=\"song_length_norm\")\n",
    "        self.inputs[\"song_length_norm\"] = self.song_length_norm_ph\n",
    "        self.song_count_quant_ph = tf.placeholder(dtype=tf.float64,shape=[None,1],name=\"song_count_quant\")\n",
    "        self.inputs[\"song_count_quant\"] = self.song_count_quant_ph\n",
    "\n",
    "        ## 定义类别特征的embedding层\n",
    "        gender_emb_layer = self.build_embedding_layer(\"gender\")\n",
    "        city_emb_layer = self.build_embedding_layer(\"city\")\n",
    "        source_type_emb_layer = self.build_embedding_layer(\"source_type\")\n",
    "        source_screen_name_emb_layer = self.build_embedding_layer(\"source_screen_name\")\n",
    "        source_system_tab_emb_layer = self.build_embedding_layer(\"source_system_tab\")\n",
    "        song_id_emb_layer = self.build_embedding_layer(\"song_id\",flatten=False)\n",
    "\n",
    "        ## dense特征\n",
    "        dense_feature_input = tf.cast(tf.concat([self.song_length_norm_ph,self.song_count_quant_ph],axis=-1),dtype=tf.float32,name=\"dense_feature\")\n",
    "\n",
    "        ## demographic feature embedding\n",
    "        city_embedding = city_emb_layer(self.city_ph)\n",
    "        gender_embedding = gender_emb_layer(self.gender_ph)\n",
    "        demographic_embedding_feature = tf.concat([city_embedding,gender_embedding],axis=-1)\n",
    "\n",
    "        ## context feature embedding\n",
    "        source_type_embedding = source_type_emb_layer(self.source_type_ph)\n",
    "        source_system_tab_embedding = source_system_tab_emb_layer(self.source_system_tab_ph)\n",
    "        source_screen_name_embedding = source_screen_name_emb_layer(self.source_screen_name_ph)\n",
    "        context_embedding_feature = tf.concat([source_type_embedding,source_system_tab_embedding,\n",
    "                                               source_screen_name_embedding],axis=-1)\n",
    "\n",
    "        ## play action seq embedding feature\n",
    "        song_play_seq_embeddings = song_id_emb_layer(self.user_play_seq_ph)\n",
    "        song_play_seq_length = tf.count_nonzero(self.user_play_seq_ph)\n",
    "        seq_avg_pooling_embedding = self.avg_pooling(song_play_seq_embeddings,song_play_seq_length)\n",
    "\n",
    "        ## concat all features\n",
    "        input_features = tf.concat([dense_feature_input,demographic_embedding_feature,\n",
    "                                    context_embedding_feature,seq_avg_pooling_embedding],axis=-1)\n",
    "\n",
    "        ## build mlp and pass the features,get the user embedding\n",
    "        self.user_embedding = self.build_mlp_layer(input_features)\n",
    "\n",
    "        ## get inference song embedding\n",
    "        inference_song_id_emb_layer = self.build_embedding_layer(\"inference_song_id\")\n",
    "        self.inference_song_weights = inference_song_id_emb_layer.embedding_matrix\n",
    "        self.inference_song_bias = tf.zeros([self.embedding_config['song_id']['vocab_size']])\n",
    "\n",
    "        self.sampled_values = tf.nn.fixed_unigram_candidate_sampler(\n",
    "            true_classes=self.label_ph,\n",
    "            num_true=1,\n",
    "            num_sampled=self.negative_sample_size,\n",
    "            unique=True,\n",
    "            range_max=self.embedding_config['song_id']['vocab_size'],\n",
    "            unigrams=self.unigrams\n",
    "        )\n",
    "\n",
    "        self.sampled_loss = tf.nn.sampled_softmax_loss(\n",
    "            weights=self.inference_song_weights,\n",
    "            biases=self.inference_song_bias,\n",
    "            labels=self.label_ph,\n",
    "            inputs=self.user_embedding,\n",
    "            num_sampled=self.negative_sample_size,\n",
    "            num_classes=self.embedding_config['song_id']['vocab_size'],\n",
    "            num_true=1,\n",
    "            sampled_values=self.sampled_values,\n",
    "            partition_strategy='div'\n",
    "        )\n",
    "        self.loss = tf.reduce_mean(self.sampled_loss)\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n",
    "\n",
    "        ## define predict op\n",
    "        self.score = tf.matmul(self.user_embedding, tf.transpose(self.inference_song_weights))  # + self.biases\n",
    "        self.predictions = tf.argmax(self.score, 1)\n",
    "        self.topk_value, self.topk_idx = tf.nn.top_k(self.score, k=self.topk)\n",
    "\n",
    "\n",
    "    def feed_feature_and_label(self, df):\n",
    "        feeds = self.feed_feature(df)\n",
    "        feeds[self.inputs[\"label\"]] = df['song_id'].values.reshape([-1, 1])\n",
    "        return feeds\n",
    "\n",
    "    def feed_feature(self, df):\n",
    "        feeds = {}\n",
    "        for field in df.columns:\n",
    "            if field in self.input_fields:\n",
    "                feeds[self.inputs[field]] = df[field].values.reshape([-1, 1])\n",
    "        seq_feature = np.concatenate(df['user_play_seq'].values).reshape([-1,self.user_play_seq_max_length])\n",
    "        feeds[self.inputs['user_play_seq']] = seq_feature\n",
    "        return feeds\n",
    "\n",
    "    def train(self,train_data):\n",
    "        train_df = train_data\n",
    "        loss_list = []\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i, df in train_df.groupby(np.arange(train_df.shape[0]) // self.batch_size):\n",
    "                _, loss = sess.run([self.train_op,self.loss],feed_dict=self.feed_feature_and_label(df))\n",
    "                loss_list.append(loss)\n",
    "\n",
    "\n",
    "    def predict_top_k(self,predict_data):\n",
    "        # logits and prediction\n",
    "        with tf.Session() as sess:\n",
    "            topk_scores, topk_idx = sess.run([self.topk_value,self.topk_idx],feed_dict=self.feed_feature(predict_data))\n",
    "            return topk_scores,topk_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = process_data(\"preprocess/train.csv\",\"feature/user_action_seq_feature.csv\",10,input_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad794890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad794890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad794890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad794890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad7a8b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad7a8b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad7a8b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad7a8b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad794890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad794890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad794890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc3ad794890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "model = YtbDNN(input_fields=input_fields,unigrams=unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
